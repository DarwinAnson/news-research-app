\
import streamlit as st
from datetime import datetime, date
from gnews import GNews
from dateutil import parser
import pandas as pd
import random
import time
import io

st.set_page_config(page_title="åŒ»è¯ä¼ä¸šæ–°é—»è°ƒç ”å·¥å…·", layout="wide")
st.title("ğŸ“Š è°·æ­Œæ–°é—»è°ƒç ”å·¥å…·")

st.markdown("""
æœ¬å·¥å…·å°†ä» **Google News** æŠ“å–æŒ‡å®šå…³é”®è¯åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ–°é—»ï¼Œ  
å¹¶ç”Ÿæˆ **Excel** ä¸ **HTML æŠ¥å‘Š** ä¾›ä¸‹è½½ã€‚  

**ä¼˜ç‚¹ï¼š**  
- å°† Daily Research çš„å·¥ä½œæµç¨‹åŒ–  
- æ ¹æ®è®¾ç½®å¥½çš„å…³é”®è¯æŒ¨ä¸ªè¿›è¡Œæ£€ç´¢æ•´ç†ï¼ŒèŠ‚çœäººåŠ›æˆæœ¬  

**ç¼ºç‚¹ï¼š**  
- æ•´ç†çš„æ–°é—»æ¥æºä»…é™è°·æ­Œæ–°é—»  
- è‹¥è°·æ­Œæ–°é—»æŸ¥ä¸åˆ°çš„ä¿¡æ¯ï¼Œå°†æ— æ³•æ”¶å½•  
""")


# -------------------------------
# ä¾§è¾¹æ è®¾ç½®
# -------------------------------
with st.sidebar:
    st.header("å‚æ•°è®¾ç½®")
    default_keywords = [
        "è¾‰ç‘", "é˜¿æ–¯åˆ©åº·", "ç½—æ°", "èµ›è¯ºè²", "è¯ºå", "è¯ºå’Œè¯ºå¾·", "æ‹œè€³",
        "å¼ºç”Ÿ", "æ­¦ç”°", "é»˜æ²™ä¸œ", "é»˜å…‹", "è‘›å…°ç´ å²å…‹", "ç¤¼æ¥",
        "å‹ƒæ—æ ¼æ®·æ ¼ç¿°", "é›…åŸ¹", "ç¾æ•¦åŠ›", "ç™¾æ—¶ç¾æ–½è´µå®", "æ¬§åŠ éš†", "å®‰æ·ä¼¦", "èµ›é»˜é£ä¸–å°”"
    ]

    st.caption("å¯åœ¨ä¸‹æ–¹è‡ªå®šä¹‰å…³é”®è¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼›ç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤æ¸…å•ï¼‰ï¼š")
    custom_kw_text = st.text_area(
        "è‡ªå®šä¹‰å…³é”®è¯ï¼ˆå¯é€‰ï¼‰",
        value="",
        height=160,
        placeholder="ä¾‹å¦‚ï¼š\nè¾‰ç‘\né˜¿æ–¯åˆ©åº·\nç½—æ°"
    )

    if custom_kw_text.strip():
        selected_keywords = [k.strip() for k in custom_kw_text.splitlines() if k.strip()]
    else:
        selected_keywords = st.multiselect("é€‰æ‹©è¦æŠ“å–çš„ä¼ä¸šå…³é”®è¯ï¼š", default_keywords, default=default_keywords[:6])

    col_a, col_b = st.columns(2)
    with col_a:
        start_date = st.date_input("å¼€å§‹æ—¥æœŸ", date(2025, 8, 5))
    with col_b:
        end_date = st.date_input("ç»“æŸæ—¥æœŸ", date(2025, 9, 8))

    max_results = st.slider("æ¯ä¸ªå…³é”®è¯æœ€å¤šæŠ“å–æ•°é‡", min_value=10, max_value=100, value=30, step=10)

    pause_min = st.slider("è¯·æ±‚é—´éš”ï¼ˆç§’ï¼Œéšæœºï¼‰â€”æœ€å°", 0.5, 5.0, 1.0, 0.5)
    pause_max = st.slider("è¯·æ±‚é—´éš”ï¼ˆç§’ï¼Œéšæœºï¼‰â€”æœ€å¤§", 1.0, 8.0, 2.0, 0.5)

    only_title_contains_keyword = st.checkbox("åªä¿ç•™æ ‡é¢˜ä¸­åŒ…å«å…³é”®è¯çš„æ–°é—»ï¼ˆæ¨èï¼‰", value=True)

# -------------------------------
# æ ¡éªŒå‚æ•°
# -------------------------------
if start_date > end_date:
    st.error("å¼€å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸã€‚è¯·é‡æ–°é€‰æ‹©ã€‚")
    st.stop()

if not selected_keywords:
    st.warning("è¯·é€‰æ‹©æˆ–è¾“å…¥è‡³å°‘ä¸€ä¸ªå…³é”®è¯ã€‚")
    st.stop()

# -------------------------------
# è¿è¡ŒæŒ‰é’®
# -------------------------------
run = st.button("ğŸš€ å¼€å§‹æŠ“å–")

if run:
    gnews_client = GNews(language='zh', country='CN', max_results=int(max_results))

    collected_news = {kw: [] for kw in selected_keywords}
    seen_titles = set()
    seen_links = set()

    progress = st.progress(0)
    status = st.empty()

    total = len(selected_keywords)
    for idx, keyword in enumerate(selected_keywords, 1):
        status.write(f"ğŸ” æŠ“å–å…³é”®è¯ï¼š**{keyword}**ï¼ˆ{idx}/{total}ï¼‰")
        results = []
        # ç®€å•é‡è¯•
        for attempt in range(2):
            try:
                results = gnews_client.get_news(keyword) or []
                if results:
                    break
            except Exception as e:
                st.warning(f"âš ï¸ ç¬¬ {attempt+1} æ¬¡è¯·æ±‚å¤±è´¥ï¼š{e}")

        for r in results:
            try:
                title = (r.get('title') or '').strip()
                link = r.get('url', '').strip()
                media = (r.get('publisher') or {}).get('title', 'æœªçŸ¥')

                date_str = r.get('published date')
                pub_date = None
                if date_str:
                    try:
                        pub_date = parser.parse(date_str)
                    except Exception:
                        pub_date = None

                pub_date_date = pub_date.date() if pub_date else datetime.today().date()

                if start_date <= pub_date_date <= end_date:
                    ok = True
                    if only_title_contains_keyword:
                        ok = (keyword.lower() in title.lower())
                    if ok and title and link and (title not in seen_titles) and (link not in seen_links):
                        news_item = {
                            'title': title,
                            'link': link,
                            'datetime': pub_date.strftime("%Y-%m-%d") if pub_date else "æœªçŸ¥æ—¥æœŸ",
                            'media': media
                        }
                        collected_news[keyword].append(news_item)
                        seen_titles.add(title)
                        seen_links.add(link)
            except Exception as e:
                st.error(f"âš ï¸ å•æ¡è§£æå¼‚å¸¸ï¼š{e}")
                continue

        # è¿›åº¦ä¸èŠ‚æµ
        progress.progress(idx / total)
        wait = random.uniform(float(pause_min), float(pause_max))
        time.sleep(wait)

    st.success("âœ… æŠ“å–å®Œæˆï¼")

    # æ±‡æ€»è¡¨
    rows = []
    for company, news_list in collected_news.items():
        for news in news_list:
            rows.append({
                "ä¼ä¸šåç§°": company,
                "å‘å¸ƒåª’ä½“": news['media'],
                "å‘å¸ƒæ—¶é—´": news['datetime'],
                "æ–°é—»æ ‡é¢˜": news['title'],
                "æ–°é—»é“¾æ¥": news['link']
            })

    if not rows:
        st.warning("âš ï¸ æ²¡æœ‰æŠ“å–åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®ã€‚è¯·å°è¯•æ‰©å¤§æ—¥æœŸèŒƒå›´æˆ–æ”¾å®½æ¡ä»¶ã€‚")
        st.stop()

    df = pd.DataFrame(rows)
    st.dataframe(df, use_container_width=True)

    # å¯¼å‡º Excel
    excel_buffer = io.BytesIO()
    df.to_excel(excel_buffer, index=False)
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½ Excel",
        data=excel_buffer.getvalue(),
        file_name=f"æ–°é—»ç­›é€‰ç»“æœ_{start_date}_to_{end_date}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

    # ç”Ÿæˆ HTML æŠ¥å‘Š
    def build_html(collected, start_date, end_date):
        html_parts = []
        html_parts.append("""<!DOCTYPE html>
<html lang="zh">
<head>
<meta charset="UTF-8">
<title>æ–°é—»ç®€æŠ¥</title>
<style>
    body { font-family: 'Microsoft YaHei', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', Arial, sans-serif; margin: 40px auto; max-width: 900px; line-height: 1.6; color: #333; }
    h1 { text-align: center; color: #2c3e50; }
    h2 { margin-top: 32px; border-bottom: 2px solid #34495e; padding-bottom: 8px; color: #34495e; }
    h3 { margin: 16px 0 10px; color: #3498db; border-left: 4px solid #3498db; padding-left: 10px;}
    ul { list-style: none; padding-left: 0; }
    li { background-color: #f8f9f9; border: 1px solid #e1e8ed; padding: 10px 15px; margin-bottom: 10px; border-radius: 6px; }
    a { text-decoration: none; color: #007acc; font-weight: bold; }
    a:hover { text-decoration: underline; }
    small { color: #888; font-size: 0.9em; }
    .summary { text-align: center; font-size: 1.05em; color: #555; background-color: #ecf0f1; padding: 12px; border-radius: 6px; margin-bottom: 24px; }
</style>
</head>
<body>""")
        html_parts.append(f"<h1>æ–°é—»ç®€æŠ¥<br><small>{start_date} è‡³ {end_date}</small></h1>\n")
        html_parts.append("<h2>è¯¦ç»†æ–°é—»åˆ—è¡¨</h2>\n")
        for keyword, news_list in collected.items():
            if news_list:
                html_parts.append(f"<h3>{keyword}</h3>\n<ul>\n")
                for item in news_list:
                    html_parts.append("<li>")
                    html_parts.append(f"<a href='{item['link']}' target='_blank'>{item['title']}</a><br>")
                    html_parts.append(f"<small>{item['datetime']} ï½œ {item['media']}</small>")
                    html_parts.append("</li>\n")
                html_parts.append("</ul>\n")
            else:
                html_parts.append(f"<h3>{keyword}</h3><p>âš ï¸ æ²¡æœ‰æŠ“å–åˆ°æ–°é—»</p>\n")
        html_parts.append("</body>\n</html>")
        return "".join(html_parts)

    html_content = build_html(collected_news, start_date, end_date)
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½ HTML æŠ¥å‘Š",
        data=html_content.encode("utf-8"),
        file_name=f"æ–°é—»ç­›é€‰ç»“æœ_{start_date}_to_{end_date}.html",
        mime="text/html"
    )

    with st.expander("æŸ¥çœ‹åˆ†ç»„ç»“æœï¼ˆæŒ‰ä¼ä¸šï¼‰"):
        for kw, news_list in collected_news.items():
            st.subheader(kw)
            if news_list:
                tmp_df = pd.DataFrame(news_list)
                st.dataframe(tmp_df, use_container_width=True)
            else:
                st.caption("æ— æ•°æ®")
